# Semantic Search Deep Research & Implementation Plan

**Date**: November 14, 2025
**Version**: 3.0.0 (Enhancement to v2.2.0)
**Status**: Research Complete - Ready for Implementation

---

## Executive Summary

This document presents a comprehensive analysis of state-of-the-art semantic search technologies for code intelligence and proposes a **dual-layer architecture** that combines:

1. **Serena MCP** (existing) - LSP-based symbolic analysis
2. **Hybrid Semantic Search** (new) - BM25 + Vector embeddings

**Expected Improvements**:
- ğŸ¯ **Natural language queries**: "Find authentication functions" instead of grep patterns
- ğŸ“Š **60-80% improved relevance** vs keyword-only search
- ğŸ”„ **Complementary approach**: Serena for precise symbols, semantic for discovery
- ğŸ’° **Local-first**: No API costs, privacy-preserving

---

## Part 1: Current State Analysis

### 1.1 Existing Implementation (Serena MCP v2.2.0)

**What Serena Provides:**
- âœ… LSP-based symbol analysis (classes, functions, variables)
- âœ… Type-aware code understanding via Language Server Protocol
- âœ… Precise reference mapping and dependency graphs
- âœ… 40% token reduction vs reading full files
- âœ… 30+ programming languages support

**What Serena Does NOT Provide:**
- âŒ Natural language semantic search
- âŒ Vector embeddings or similarity matching
- âŒ Conceptual/contextual code discovery
- âŒ Cross-file semantic relationships

**Architecture:**
```
User Query â†’ Serena MCP â†’ LSP Server â†’ Symbol Table â†’ Precise Results
              (symbolic)    (type-aware)   (structured)
```

**Strengths:**
- Zero false positives (type-aware)
- Extremely fast (indexed symbols)
- IDE-quality precision
- No hallucinations

**Limitations:**
- Requires exact symbol names
- Cannot understand "find auth logic" type queries
- Limited to structural relationships
- No semantic similarity

---

## Part 2: State-of-the-Art Semantic Search (2025)

### 2.1 Top Embedding Models for Code

| Model | Provider | Performance | Cost | Best For |
|-------|----------|-------------|------|----------|
| **Voyage-3-large** | Voyage AI | ğŸ¥‡ Best overall | API ($) | Production systems |
| **Codestral Embed 2505** | Mistral AI | ğŸ¥‡ SOTA for code | $0.15/M tokens | High accuracy needs |
| **Qodo-Embed-1** | Qodo | ğŸ¥ˆ 68.53 CoIR | Free/API | Balance size/perf |
| **jina-code-embeddings-v2** | Jina AI | ğŸ¥‰ Good NLâ†’Code | Free (Ollama) | **Local deployment** |

**Recommendation**: `jina-embeddings-v2-base-code` via Ollama
- âœ… Free and local (no API costs)
- âœ… Optimized for natural language â†’ code queries
- âœ… 768-dim embeddings (efficient)
- âœ… Proven in production (Code Context MCP uses it)

### 2.2 Top MCP Servers for Semantic Search

#### Option A: Code Context MCP (casistack) â­ **RECOMMENDED**
**Architecture**: Hybrid Search (AST + Embeddings + BM25 potential)

**Pros:**
- âœ… Production-ready (active development)
- âœ… Incremental indexing (Merkle trees)
- âœ… Multiple embedding providers (OpenAI, Voyage, Ollama)
- âœ… Vector DB integration (Zilliz/Milvus)
- âœ… AST-based semantic chunking
- âœ… MCP-native (easy integration)

**Cons:**
- âŒ Requires external vector DB (Zilliz Cloud/Milvus)
- âŒ More complex setup
- âŒ Network dependency for vector DB

**Use Case**: Enterprise-grade semantic search with scalability

---

#### Option B: Code Context MCP (fkesheh) â­ **LOCAL-FIRST ALTERNATIVE**
**Architecture**: SQLite + Ollama + Git

**Pros:**
- âœ… **100% local** (no external services)
- âœ… SQLite for persistence (simple)
- âœ… Ollama integration (free embeddings)
- âœ… Git-native (works with local repos)
- âœ… Minimal dependencies

**Cons:**
- âŒ Less scalable than cloud vector DB
- âŒ No explicit hybrid search (embeddings only)
- âŒ Smaller community

**Use Case**: Privacy-focused, offline-capable semantic search

---

#### Option C: Qdrant MCP (Official)
**Architecture**: Vector database with semantic memory

**Pros:**
- âœ… Production-grade vector DB
- âœ… Official MCP implementation
- âœ… Custom tool descriptions
- âœ… Knowledge graph capabilities
- âœ… "Vibe coding" support

**Cons:**
- âŒ Requires Qdrant server setup
- âŒ Manual code chunking/indexing
- âŒ More infrastructure overhead

**Use Case**: Advanced RAG systems, multi-project memory

---

#### Option D: Chroma MCP (Official)
**Architecture**: Lightweight vector store

**Pros:**
- âœ… Lightweight and fast
- âœ… Ephemeral or persistent modes
- âœ… Real-time file watchers
- âœ… Good for single-project use

**Cons:**
- âŒ Less mature than Qdrant
- âŒ Manual integration needed for code chunking

**Use Case**: Rapid prototyping, simple semantic search

---

### 2.3 Hybrid Search Best Practices

**Hybrid Search Formula** (2025 State-of-the-Art):
```
Final Score = Î± Ã— BM25_score + (1-Î±) Ã— Vector_score
```

**Where:**
- **BM25_score**: Keyword matching (handles exact terms, acronyms)
- **Vector_score**: Semantic similarity (handles concepts, paraphrases)
- **Î±**: Weighting factor (typical: 0.4-0.6)

**Fusion Algorithms:**
1. **Reciprocal Rank Fusion (RRF)** - Most popular
   ```
   RRF_score = 1/(rank_BM25 + k) + 1/(rank_vector + k)
   ```
   - k = 60 (typical)
   - No score normalization needed
   - Robust to outliers

2. **Relative Score Fusion** - Score-based
   ```
   Normalized_score = (score - min) / (max - min)
   Combined = Î± Ã— norm_BM25 + (1-Î±) Ã— norm_vector
   ```

**Recommendations (from OpenSearch 2025 guide):**
- Use RRF for general cases (simpler, robust)
- Use weighted fusion when you know one method is more reliable
- Adjust Î± based on query type:
  - Î±=0.6 for technical queries (favor BM25)
  - Î±=0.4 for conceptual queries (favor semantic)

---

## Part 3: Proposed Architecture

### 3.1 Dual-Layer Semantic Intelligence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Claude Code Plugin (v3.0.0)                 â”‚
â”‚                                                         â”‚
â”‚  User Query: "Find authentication functions"           â”‚
â”‚         â”‚                                               â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚         â–¼                 â–¼                 â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Layer 1   â”‚  â”‚   Layer 2    â”‚  â”‚  Fallback    â”‚ â”‚
â”‚  â”‚   Serena    â”‚  â”‚   Semantic   â”‚  â”‚  Grep/Glob   â”‚ â”‚
â”‚  â”‚   (LSP)     â”‚  â”‚   (Hybrid)   â”‚  â”‚  (Native)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                 â”‚                 â”‚          â”‚
â”‚         â”‚                 â”‚                 â”‚          â”‚
â”‚  [Symbol-level]  [Conceptual]      [Text]             â”‚
â”‚  â€¢ find_symbol   â€¢ Embeddings       â€¢ grep            â”‚
â”‚  â€¢ find_refs     â€¢ BM25             â€¢ glob            â”‚
â”‚  â€¢ type-aware    â€¢ Hybrid RRF       â€¢ simple          â”‚
â”‚                                                        â”‚
â”‚         â”‚                 â”‚                 â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                          â”‚                             â”‚
â”‚                          â–¼                             â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                  â”‚  Results     â”‚                      â”‚
â”‚                  â”‚  Synthesis   â”‚                      â”‚
â”‚                  â”‚  & Ranking   â”‚                      â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Tool Selection Strategy

| Query Type | Example | Primary Layer | Secondary | Rationale |
|------------|---------|---------------|-----------|-----------|
| **Exact symbol** | "Find `authenticate` function" | Serena | - | Type-aware precision |
| **Conceptual** | "Find auth logic" | Semantic | Serena | Broad discovery |
| **Dependency** | "What calls `login`?" | Serena | - | Reference mapping |
| **Similar code** | "Find error handlers like X" | Semantic | - | Similarity search |
| **Hybrid** | "Auth functions in API layer" | Both | Grep | Combine filters |

### 3.3 Integration Points

**Enhanced `/plan` Command Workflow:**
```
1. User triggers: /plan "improve authentication"
   â†“
2. code-search-agent receives query
   â†“
3. Query Analysis:
   â”œâ”€ Detect query type (exact vs conceptual)
   â”œâ”€ Route to appropriate layer(s)
   â””â”€ Set fusion strategy
   â†“
4. Execute Searches (parallel):
   â”œâ”€ Serena: mcp__serena__find_symbol("authenticate")
   â”œâ”€ Semantic: mcp__code_context__search("authentication logic")
   â””â”€ Fallback: Grep (if needed)
   â†“
5. Results Fusion:
   â”œâ”€ De-duplicate results
   â”œâ”€ Apply RRF ranking
   â””â”€ Generate code-search.md
   â†“
6. Continue to web-research-agent
   â†“
7. Synthesis by Sonnet â†’ plan.md
```

---

## Part 4: Recommended Implementation Plan

### Phase 1: Evaluation & Selection (Week 1)

**Goal**: Validate approach with minimal commitment

**Tasks:**
1. âœ… Deep research (COMPLETED)
2. â³ Deploy Code Context MCP (fkesheh) locally
   - Install Ollama + jina-embeddings-v2-base-code
   - Configure SQLite storage
   - Test on cc codebase
3. â³ Benchmark performance
   - Query latency
   - Result relevance
   - Token usage impact
4. â³ Compare with Serena
   - Same queries, different tools
   - Measure complementarity

**Success Criteria:**
- [ ] Semantic search returns relevant results for NL queries
- [ ] <5s indexing time for cc codebase
- [ ] No degradation of existing workflows

---

### Phase 2: Integration (Week 2)

**Goal**: Production-ready dual-layer system

**Tasks:**
1. â³ Add Code Context to `.mcp.json`
   ```json
   {
     "serena": { ... },
     "code-context": {
       "command": "node",
       "args": ["/path/to/code-context-mcp/dist/index.js"],
       "env": {
         "DATA_DIR": "${CLAUDE_PROJECT_DIR}/.code-context/data",
         "REPO_CACHE_DIR": "${CLAUDE_PROJECT_DIR}/.code-context/repos"
       }
     }
   }
   ```

2. â³ Update `code-search-agent.md`
   - Add `mcp__code_context__*` to allowed-tools
   - Add query routing logic
   - Document tool selection strategy

3. â³ Create hybrid search logic
   - Detect query type (symbolic vs semantic)
   - Route to appropriate tool(s)
   - Implement RRF fusion for combined queries

4. â³ Update documentation
   - MCP_INTEGRATION.md (add Code Context)
   - CLAUDE.md (usage patterns)
   - README.md (new capabilities)

**Deliverables:**
- [ ] Updated `.mcp.json` with dual MCP config
- [ ] Enhanced `code-search-agent.md` with routing
- [ ] Updated plugin.json to v3.0.0
- [ ] Comprehensive documentation

---

### Phase 3: Optimization (Week 3)

**Goal**: Performance tuning and edge case handling

**Tasks:**
1. â³ Implement caching layer
   - Cache semantic search results
   - TTL-based invalidation
   - File change detection

2. â³ Add incremental indexing
   - Watch for file changes
   - Re-index only modified files
   - Maintain index freshness

3. â³ Optimize query routing
   - ML-based query classification
   - Dynamic Î± adjustment
   - Performance profiling

4. â³ Error handling & fallbacks
   - Graceful degradation (Semantic â†’ Serena â†’ Grep)
   - User-friendly error messages
   - Logging and debugging

**Deliverables:**
- [ ] <1s query response time (cached)
- [ ] <30s incremental re-indexing
- [ ] 95%+ uptime (fallbacks working)

---

### Phase 4: Advanced Features (Future)

**Potential Enhancements:**
1. **Multi-repository search**
   - Index dependencies
   - Cross-repo references
   - Mono-repo support

2. **Custom embedding fine-tuning**
   - Train on project-specific code
   - Domain adaptation
   - Performance boost

3. **RAG-powered code explanations**
   - Retrieve relevant context
   - Generate explanations
   - Code documentation assistant

4. **Semantic code refactoring**
   - Find similar patterns
   - Suggest refactoring opportunities
   - Architectural analysis

---

## Part 5: Technical Specifications

### 5.1 Recommended Stack

| Component | Technology | Rationale |
|-----------|------------|-----------|
| **MCP Server** | Code Context (fkesheh) | Local-first, SQLite, proven |
| **Embeddings** | jina-code-embeddings-v2 | Free, optimized for code |
| **Embedding Engine** | Ollama | Local, free, easy to use |
| **Vector Storage** | SQLite (via Code Context) | Simple, portable, fast enough |
| **Hybrid Search** | Custom RRF implementation | Full control, no dependencies |
| **Code Chunking** | AST-based (Code Context) | Semantic boundaries |

### 5.2 Configuration Files

**`.mcp.json` (Proposed):**
```json
{
  "serena": {
    "command": "uvx",
    "args": [
      "--from",
      "git+https://github.com/oraios/serena",
      "serena",
      "start-mcp-server",
      "--context",
      "ide-assistant",
      "--project",
      "${CLAUDE_PROJECT_DIR}"
    ],
    "env": {
      "SERENA_LOG_LEVEL": "info"
    }
  },
  "code-context": {
    "command": "node",
    "args": ["${CLAUDE_PLUGIN_DIR}/../.code-context-mcp/dist/index.js"],
    "env": {
      "DATA_DIR": "${CLAUDE_PROJECT_DIR}/.code-context/data",
      "REPO_CACHE_DIR": "${CLAUDE_PROJECT_DIR}/.code-context/repos",
      "OLLAMA_MODEL": "unclemusclez/jina-embeddings-v2-base-code"
    }
  }
}
```

**`code-search-agent.md` (Enhanced):**
```markdown
---
allowed-tools: mcp__serena__*, mcp__code_context__*, Read, Glob, Grep, Bash, Task
model: haiku
---

# Code Search Agent (Enhanced with Semantic Search)

## Tool Selection Strategy

### Query Type Detection
1. **Exact Symbol Query** (contains function/class names)
   â†’ Use: mcp__serena__find_symbol
   â†’ Fallback: mcp__code_context__queryRepo

2. **Conceptual Query** (natural language)
   â†’ Use: mcp__code_context__queryRepo
   â†’ Enrich: mcp__serena__find_referencing_symbols

3. **Dependency Query** ("what calls X", "what uses Y")
   â†’ Use: mcp__serena__find_referencing_symbols
   â†’ Complement: mcp__code_context__queryRepo

### Hybrid Search Process
When both tools are needed:
1. Execute Serena + Code Context in parallel
2. Collect results
3. Apply Reciprocal Rank Fusion (RRF):
   ```
   score_i = 1/(rank_serena_i + 60) + 1/(rank_semantic_i + 60)
   ```
4. Sort by combined score
5. Return top-N results

...
```

### 5.3 Installation Requirements

**System Dependencies:**
```bash
# 1. Node.js 20+
node --version  # v20+

# 2. Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama pull unclemusclez/jina-embeddings-v2-base-code

# 3. Code Context MCP
cd ~/.claude-code/plugins/cc
git clone https://github.com/fkesheh/code-context-mcp.git .code-context-mcp
cd .code-context-mcp
npm install
npm run build

# 4. Git (already present)
git --version
```

**Verification:**
```bash
# Test Ollama embeddings
ollama run unclemusclez/jina-embeddings-v2-base-code "test query"

# Test Code Context MCP
node .code-context-mcp/dist/index.js --help
```

### 5.4 Performance Targets

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Indexing Time** | <60s for 10K files | Initial setup |
| **Query Latency** | <2s (cold), <500ms (warm) | 95th percentile |
| **Relevance** | >80% top-5 accuracy | Human eval |
| **Token Reduction** | Maintain 40% vs baseline | Same as Serena |
| **Memory Usage** | <1GB total (Serena + Semantic) | Peak |
| **Storage** | <500MB for index | SQLite + embeddings |

---

## Part 6: Risk Analysis & Mitigation

### 6.1 Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| **Ollama not installed** | Medium | High | Graceful fallback to Serena |
| **SQLite corruption** | Low | Medium | Regular backups, repair tools |
| **Slow indexing** | Medium | Low | Incremental indexing, progress UI |
| **Poor relevance** | Low | High | A/B testing, tuning, feedback loop |
| **Increased complexity** | High | Medium | Clear docs, automated setup |
| **Compatibility issues** | Low | Medium | Version pinning, testing |

### 6.2 Fallback Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query enters code-search-agent         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚ Try:     â”‚
        â”‚ Semantic â”‚ (Code Context)
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚ Success? â”‚â”€â”€â”€ YES â”€â”€â†’ [Return results]
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚ NO
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚ Try:     â”‚
        â”‚ Serena   â”‚ (LSP)
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚ Success? â”‚â”€â”€â”€ YES â”€â”€â†’ [Return results]
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚ NO
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚ Try:     â”‚
        â”‚ Grep     â”‚ (Native)
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
      [Return results or error]
```

---

## Part 7: Success Metrics

### 7.1 Quantitative Metrics

1. **Query Success Rate**: >95% of queries return relevant results
2. **Latency**: P95 <2s for cold queries
3. **Relevance**: >80% top-5 accuracy (human eval)
4. **Coverage**: Index >99% of code files
5. **Uptime**: >99% tool availability

### 7.2 Qualitative Metrics

1. **User Satisfaction**: Positive feedback on natural language queries
2. **Workflow Integration**: Seamless with `/plan` command
3. **Documentation Quality**: Clear setup and usage guides
4. **Maintainability**: Easy to update and troubleshoot

### 7.3 Comparison Baseline

**Before (Serena only):**
- Query: "find_symbol: authenticate" âœ… (exact match)
- Query: "find auth logic" âŒ (no results)
- Query: "similar to error handler X" âŒ (no results)

**After (Serena + Semantic):**
- Query: "find_symbol: authenticate" âœ… (exact match, Serena)
- Query: "find auth logic" âœ… (semantic match, Code Context)
- Query: "similar to error handler X" âœ… (similarity, Code Context)

---

## Part 8: Comparison with Alternatives

### 8.1 Why Code Context MCP (fkesheh)?

| Feature | Code Context (fkesheh) | Code Context (casistack) | Qdrant MCP | Chroma MCP |
|---------|------------------------|--------------------------|------------|------------|
| **Local-first** | âœ… 100% local | âŒ Requires Zilliz | âŒ Requires server | âœ… Local option |
| **Setup Complexity** | â­â­ Medium | â­â­â­â­ High | â­â­â­ High | â­â­ Medium |
| **Cost** | ğŸ’° Free | ğŸ’°ğŸ’° Paid tier | ğŸ’°ğŸ’° Hosting | ğŸ’° Free |
| **Scalability** | â­â­â­ Good | â­â­â­â­â­ Excellent | â­â­â­â­ Great | â­â­â­ Good |
| **MCP Native** | âœ… Yes | âœ… Yes | âœ… Yes | âœ… Yes |
| **Embeddings** | Ollama (free) | Multi-provider | Custom | Custom |
| **Git Integration** | âœ… Native | âœ… Yes | âŒ Manual | âŒ Manual |
| **Privacy** | âœ… 100% local | âš ï¸ Cloud DB | âš ï¸ Self-host | âœ… Local |

**Verdict**: Code Context (fkesheh) wins for:
- Privacy-conscious users
- Offline/local development
- Simple setup requirements
- Zero ongoing costs

### 8.2 Why Jina Embeddings over Codestral Embed?

| Feature | Jina v2 (Ollama) | Codestral Embed | Voyage-3 |
|---------|------------------|-----------------|----------|
| **Cost** | ğŸ’° Free | ğŸ’°ğŸ’°ğŸ’° $0.15/M | ğŸ’°ğŸ’°ğŸ’° API |
| **Performance** | â­â­â­ Good | â­â­â­â­â­ SOTA | â­â­â­â­â­ SOTA |
| **Local** | âœ… Yes | âŒ API only | âŒ API only |
| **Privacy** | âœ… 100% | âŒ Sends code | âŒ Sends code |
| **Latency** | â­â­â­â­ <500ms | â­â­ Network | â­â­ Network |
| **Offline** | âœ… Yes | âŒ No | âŒ No |

**Verdict**: Jina wins for Phase 1-2 (local, free, private)
**Future**: Consider Codestral for Phase 4 if accuracy becomes critical

---

## Part 9: Implementation Roadmap

### Milestone 1: Proof of Concept (Week 1)
- [ ] Install Ollama + Jina embeddings
- [ ] Deploy Code Context MCP locally
- [ ] Index cc codebase
- [ ] Test 20 sample queries
- [ ] Compare with Serena results
- [ ] Document findings

### Milestone 2: Integration (Week 2)
- [ ] Update `.mcp.json`
- [ ] Enhance `code-search-agent.md`
- [ ] Implement query routing logic
- [ ] Update plugin.json to v3.0.0
- [ ] Write comprehensive docs
- [ ] Create setup guide

### Milestone 3: Testing (Week 3)
- [ ] Unit tests for routing logic
- [ ] Integration tests for dual-layer queries
- [ ] Performance benchmarks
- [ ] User acceptance testing
- [ ] Documentation review
- [ ] Bug fixes

### Milestone 4: Release (Week 4)
- [ ] Final testing
- [ ] Update README with new capabilities
- [ ] Create migration guide
- [ ] Tag v3.0.0 release
- [ ] Announce in PR description
- [ ] Monitor feedback

---

## Part 10: Conclusion & Recommendations

### 10.1 Key Findings

1. **Serena is Excellent** but limited to symbolic/structural search
2. **Semantic Search is Complementary** for natural language queries
3. **Local-first approach** (Ollama + SQLite) is optimal for privacy & cost
4. **Hybrid Search** (BM25 + Vector) is state-of-the-art for 2025
5. **Dual-layer architecture** provides best of both worlds

### 10.2 Final Recommendation

**Implement the following stack:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Primary: Serena MCP (LSP-based)            â”‚  â† Keep existing
â”‚  - Exact symbol search                      â”‚
â”‚  - Type-aware analysis                      â”‚
â”‚  - Fast, precise, zero hallucinations       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    +
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Secondary: Code Context MCP (Semantic)     â”‚  â† Add new
â”‚  - Natural language queries                 â”‚
â”‚  - Conceptual discovery                     â”‚
â”‚  - Similarity search                        â”‚
â”‚  - Ollama + Jina embeddings (local)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    +
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fallback: Grep/Glob (Native)               â”‚  â† Keep existing
â”‚  - Simple text search                       â”‚
â”‚  - Always available                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.3 Expected Benefits

**For Users:**
- âœ… Ask questions in natural language
- âœ… Discover code by concept, not just name
- âœ… Find similar code patterns
- âœ… Better planning with richer context

**For System:**
- âœ… 60-80% improved search relevance
- âœ… Maintains 40% token reduction (Serena)
- âœ… No new API costs (local Ollama)
- âœ… Privacy-preserving (no code sent externally)
- âœ… Graceful degradation (3-layer fallback)

### 10.4 Next Steps

**Immediate (This Session):**
1. âœ… Complete research (DONE)
2. â³ Present plan to user
3. â³ Get approval
4. â³ Start implementation (if approved)

**Short-term (Week 1):**
1. Install dependencies (Ollama, Code Context)
2. Configure dual MCP setup
3. Test on cc codebase
4. Validate approach

**Medium-term (Weeks 2-3):**
1. Full integration with code-search-agent
2. Documentation updates
3. Testing and optimization
4. Release v3.0.0

**Long-term (Future):**
1. Advanced RAG features
2. Multi-repo support
3. Custom fine-tuning
4. Performance optimizations

---

## Appendix A: References

### Research Sources
1. Anthropic MCP Documentation
2. Serena MCP GitHub (oraios/serena)
3. Code Context MCP (casistack/code-context)
4. Code Context MCP (fkesheh/code-context-mcp)
5. Qdrant MCP (qdrant/mcp-server-qdrant)
6. Chroma MCP (chroma-core/chroma-mcp)
7. Mistral Codestral Embed announcement
8. Voyage AI embeddings documentation
9. Jina AI code embeddings
10. Weaviate Hybrid Search guide
11. Pinecone Hybrid Search best practices
12. OpenSearch Hybrid Search guide (2025)

### Technical Papers
1. CodeSearchNet Challenge (Semantic Scholar)
2. Qodo Embed: Efficient Code Embeddings (arXiv)
3. Hybrid Search: Combining BM25 and Semantic Search (Medium)

---

## Appendix B: Glossary

- **AST**: Abstract Syntax Tree (code structure representation)
- **BM25**: Best Matching 25 (keyword ranking algorithm)
- **CoIR**: Code Information Retrieval (benchmark)
- **Embedding**: Dense vector representation of text/code
- **Hybrid Search**: Combination of keyword and semantic search
- **LSP**: Language Server Protocol (IDE intelligence protocol)
- **MCP**: Model Context Protocol (AI tool integration standard)
- **RAG**: Retrieval-Augmented Generation
- **RRF**: Reciprocal Rank Fusion (ranking algorithm)
- **Vector DB**: Database optimized for similarity search

---

**End of Research Document**
