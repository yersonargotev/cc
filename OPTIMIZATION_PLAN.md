# Plan de Mejora: Comandos y Agentes - Versi√≥n Inteligente y Eficiente

**Fecha:** 2025-11-12
**Objetivo:** Reducir tokens, mejorar accuracy, mantener 200-300 l√≠neas m√°ximo
**Meta de Reducci√≥n:** 40% de tokens (benchmark recomendado 2025)

---

## üìä Estado Actual vs. Objetivo

| Archivo | L√≠neas Actuales | Objetivo | Estado | Reducci√≥n Necesaria |
|---------|----------------|----------|---------|---------------------|
| `plan.md` | **471** üî¥ | 250-300 | CR√çTICO | -36% a -47% |
| `code.md` | **133** üü° | 100-120 | OPTIMIZABLE | -10% a -25% |
| `commit.md` | **57** ‚úÖ | 50-80 | √ìPTIMO | Mantener |
| `code-search-agent.md` | **72** ‚úÖ | 60-80 | √ìPTIMO | Refinamiento menor |
| `web-research-agent.md` | **63** ‚úÖ | 60-80 | √ìPTIMO | Refinamiento menor |

**Prioridad de Intervenci√≥n:**
1. üî¥ **CR√çTICO**: `plan.md` (471 ‚Üí ~280 l√≠neas, -40%)
2. üü° **MEDIO**: `code.md` (133 ‚Üí ~110 l√≠neas, -17%)
3. üü¢ **BAJO**: Agentes (ya est√°n en rango √≥ptimo)

---

## üî¨ Hallazgos de Investigaci√≥n (2025 Best Practices)

### Principios Clave de Eficiencia

#### 1. **Token Optimization** (Anthropic + OpenAI)
- ‚úÖ Prompts concisos reducen tokens **30-50%** sin p√©rdida de calidad
- ‚úÖ Desaf√≠o validado: cortar 40% y hacer A/B testing
- ‚úÖ Prompts >500 palabras muestran **rendimientos decrecientes**
- ‚úÖ Listas numeradas/bullets mejoran parsing **+44% accuracy**

#### 2. **Longitud √ìptima por Complejidad**
- **Tareas complejas**: 150-300 palabras (prompts multi-fase)
- **Tareas est√°ndar**: 50-150 palabras (operaciones simples)
- **Micro-tareas**: <50 palabras (comandos at√≥micos)

#### 3. **Estructuras de Alto Rendimiento**
```markdown
‚úÖ HACER:
- Tags sem√°nticos: <task>, <context>, <output>
- Instrucciones positivas: "Output X" (no "Don't output Y")
- L√≠mites expl√≠citos: "M√°ximo 200 palabras", "Top 5 resultados"
- Prompt chaining: dividir tareas complejas en pasos secuenciales

‚ùå EVITAR:
- Instrucciones negativas ("no hagas...")
- Repetici√≥n de conceptos
- Descripciones vagas sin ejemplos concretos
- Templates con secciones opcionales no utilizadas
```

#### 4. **Context Engineering**
> "Good context engineering means finding the **smallest possible set of high-signal tokens** that maximize the likelihood of some desired outcome."
> ‚Äî Anthropic, 2025

#### 5. **Caching Estrat√©gico**
- Prompt caching reduce costos **75-90%** en contextos repetitivos
- Usar para: documentaci√≥n base, ejemplos de formato, definiciones de herramientas

---

## üéØ Estrategias de Optimizaci√≥n

### Estrategia 1: **Eliminaci√≥n de Verbosidad** (Target: -30% tokens)

#### T√©cnicas Espec√≠ficas:

**A. Compresi√≥n de Instrucciones**
```markdown
‚ùå ANTES (verbose):
"You should carefully analyze the codebase to understand the current implementation
patterns and identify any relevant files that might be related to the user's request.
Make sure to look at both the structure and the content of the files."

‚úÖ DESPU√âS (conciso):
"Analyze codebase: structure + content. Identify files relevant to request."
```

**B. Templates Impl√≠citos vs. Expl√≠citos**
```markdown
‚ùå ANTES (expl√≠cito completo):
## Session Information
- ID: {session_id}
- Created: {timestamp}
- Status: {status}

## Context Analysis
### Code Findings
- [Detailed findings here]
### Web Research
- [Detailed findings here]

‚úÖ DESPU√âS (directivas + ejemplo):
<output_format>
Use markdown with: Session Info, Context Analysis (code + web), Implementation Steps.
Example: [Minimal but complete example with 3-4 lines]
</output_format>
```

**C. Consolidaci√≥n de Secciones Redundantes**
- Combinar "Gap Analysis" + "Risk Assessment" ‚Üí "Risks & Gaps"
- Fusionar "Testing Strategy" + "Success Criteria" ‚Üí "Validation Plan"
- Integrar "Timeline Estimates" en cada paso de implementaci√≥n

---

### Estrategia 2: **Structured Prompting** (Target: +44% accuracy)

#### Transformaci√≥n de Formato:

**A. Usar Tags Sem√°nticos (Claude-optimized)**
```markdown
‚úÖ ESTRUCTURA NUEVA:

<task>
Create implementation plan integrating code analysis + web research
</task>

<context>
- Session ID: $SESSION_ID
- Files available: code-search.md, web-research.md
- Output: plan.md (concise, actionable)
</context>

<requirements>
1. Integrate findings from both sources
2. Prioritize by impact (üî¥üü°üü¢)
3. Include evidence (file:line or URL)
4. Max 300 lines total
</requirements>

<output_format>
[Minimal complete example - 5 lines showing structure]
</output_format>
```

**B. Principio "Show, Don't Tell"**
```markdown
‚ùå ANTES:
"Each finding should include the file path with line number in the format file:line,
and should provide specific details about what was found."

‚úÖ DESPU√âS:
Example finding format:
- `auth/login.ts:42` - JWT validation missing expiry check
```

---

### Estrategia 3: **Instruction Hierarchy** (Target: mejor ejecuci√≥n)

#### Niveles de Prioridad:

```markdown
<critical>
MUST requirements - failure = task incomplete
</critical>

<important>
SHOULD requirements - omission degrades quality
</important>

<optional>
MAY requirements - nice-to-have enhancements
</optional>
```

**Aplicaci√≥n:**
- üî¥ CRITICAL: Evidencia (file:line/URLs), formato de salida, l√≠mite de tokens
- üü° IMPORTANT: Priorizaci√≥n, an√°lisis de riesgos
- üü¢ OPTIONAL: Timeline estimates, documentaci√≥n adicional

---

### Estrategia 4: **Prompt Chaining** (Target: mejor accuracy en tareas complejas)

#### Reestructuraci√≥n de `plan.md`:

**ANTES (monol√≠tico - 471 l√≠neas):**
```
/plan ‚Üí [TODO: setup + research + synthesis + plan generation + reporting]
```

**DESPU√âS (modular - ~280 l√≠neas):**
```
/plan ‚Üí
  1. Setup session (bash commands) [20 lines]
  2. Trigger parallel research (Task x2) [40 lines]
  3. Synthesize + generate plan [180 lines] ‚Üê CORE LOGIC
  4. Report to user [40 lines]
```

**Beneficios:**
- Cada fase tiene objetivo claro y verificable
- Reduce carga cognitiva del modelo
- Permite optimizaci√≥n independiente de cada fase

---

### Estrategia 5: **Meta-Prompting** (Target: auto-mejora continua)

#### Sistema de Feedback Loop:

```markdown
<evaluation_criteria>
After execution, assess:
1. Token efficiency: Did we stay under 300 lines?
2. Accuracy: Did output match requirements?
3. Completeness: Any missing critical info?
</evaluation_criteria>

<self_correction>
If criteria not met, iterate once with adjusted parameters.
</self_correction>
```

---

## üîß Plan de Implementaci√≥n Espec√≠fico

### FASE 1: Optimizaci√≥n Cr√≠tica - `plan.md` üî¥

**Objetivo:** 471 ‚Üí 280 l√≠neas (-40%)

#### Paso 1.1: Comprimir Session Setup (44 ‚Üí 20 l√≠neas)
```markdown
CAMBIOS:
- Eliminar comentarios explicativos redundantes
- Usar bash one-liners en vez de multi-l√≠nea
- Template CLAUDE.md: de 15 l√≠neas ‚Üí 8 l√≠neas (solo estructura)
```

#### Paso 1.2: Comprimir Research Phase (85 ‚Üí 40 l√≠neas)
```markdown
CAMBIOS:
- Reducir prompts de subagentes: usar referencias en vez de repetir instrucciones
- code-search prompt: de ~30 l√≠neas ‚Üí 15 l√≠neas
- web-research prompt: de ~30 l√≠neas ‚Üí 15 l√≠neas
T√âCNICA: "Ver agents/code-search-agent.md para detalles" en vez de repetir todo
```

#### Paso 1.3: Comprimir Plan Template (426 ‚Üí 180 l√≠neas) ‚ö° **MAYOR IMPACTO**
```markdown
CAMBIOS:

A. Consolidar Secciones (20 ‚Üí 10 secciones):
   ANTES:
   1. Session Information
   2. Context Analysis
   3. Current State
   4. Available Information
   5. Gap Analysis
   6. Risk Assessment
   7. Implementation Strategy
   8. Step-by-Step Implementation
   9. Testing Strategy
   10. Risk Mitigation
   11. Documentation Updates
   12. Success Criteria
   13. Timeline Estimates
   14. References

   DESPU√âS:
   1. Session & Context (fusi√≥n de 1+2+3+4)
   2. Risks & Gaps (fusi√≥n de 5+6+10)
   3. Implementation Plan (fusi√≥n de 7+8 - m√°s conciso)
   4. Validation (fusi√≥n de 9+12)
   5. References & Timeline (fusi√≥n de 11+13+14)

B. Usar Templates Impl√≠citos:
   - Dar 1 ejemplo completo de cada secci√≥n (5 l√≠neas)
   - Eliminar secciones repetitivas con "..."
   - Confiar en capacidad del modelo para seguir patrones

C. Tags Sem√°nticos:
   <session_info>, <risks>, <implementation>, <validation>, <references>

D. L√≠mites Expl√≠citos:
   - "Each implementation step: max 3 sub-tasks"
   - "Risk assessment: top 5 risks only"
   - "References: essential links only (max 10)"
```

#### Paso 1.4: Comprimir User Reporting (32 ‚Üí 20 l√≠neas)
```markdown
CAMBIOS:
- Eliminar formato ASCII art/separadores decorativos
- Comprimir resumen: bullet points en vez de p√°rrafos
- M√©tricas en tabla de 1 l√≠nea en vez de lista
```

#### Paso 1.5: Comprimir Quality Standards (11 ‚Üí 20 l√≠neas)
```markdown
CAMBIOS:
- Consolidar 7 assertions en 3-4 grupos tem√°ticos
- Usar formato compacto: "‚úÖ Category: req1, req2, req3"
```

**Resultado Esperado:** 471 ‚Üí 280 l√≠neas ‚úÖ

---

### FASE 2: Optimizaci√≥n Media - `code.md` üü°

**Objetivo:** 133 ‚Üí 110 l√≠neas (-17%)

#### Paso 2.1: Comprimir Session Validation (30 ‚Üí 15 l√≠neas)
```markdown
CAMBIOS:
- Bash validation: 3 comandos ‚Üí 1 comando compound
- Eliminar echo statements redundantes
- Usar exit codes en vez de mensajes verbose
```

#### Paso 2.2: Comprimir Implementation Principles (40 ‚Üí 25 l√≠neas)
```markdown
CAMBIOS:
- De 8 principios detallados ‚Üí 5 principios core
- Eliminar ejemplos inline (confiar en experiencia del modelo)
- Usar bullets de 1 l√≠nea en vez de p√°rrafos
```

#### Paso 2.3: Comprimir Deliverables Template (50 ‚Üí 30 l√≠neas)
```markdown
CAMBIOS:
- code.md template: de estructura detallada ‚Üí ejemplo completo mini
- Eliminar secciones opcionales del template
- Usar "see plan.md for context" en vez de repetir
```

**Resultado Esperado:** 133 ‚Üí 110 l√≠neas ‚úÖ

---

### FASE 3: Refinamiento Menor - Agentes üü¢

**Objetivo:** Mantener 60-80 l√≠neas, mejorar claridad

#### Paso 3.1: `code-search-agent.md` (72 l√≠neas)
```markdown
MEJORAS:
- Consolidar 5 categor√≠as de b√∫squeda en 3 m√°s amplias
- Output template: de ejemplo detallado ‚Üí directiva + micro-ejemplo
- Eliminar explicaciones de herramientas (ya est√°n en metadata)
```

#### Paso 3.2: `web-research-agent.md` (63 l√≠neas)
```markdown
MEJORAS:
- Comprimir lista de MCP tools (usar "prefer mcp__* tools")
- Output template: mismo tratamiento que code-search
- Consolidar quality assertions
```

**Resultado Esperado:** 72 ‚Üí 65 l√≠neas, 63 ‚Üí 58 l√≠neas ‚úÖ

---

### FASE 4: Mejoras de Sistema üéØ

#### Paso 4.1: Implementar Caching Estrat√©gico
```markdown
ACCI√ìN:
- Identificar secciones est√°ticas en prompts (templates, ejemplos)
- Marcar para prompt caching (si disponible en API)
- Documentar en CLAUDE.md qu√© secciones son cacheable
```

#### Paso 4.2: A/B Testing Framework
```markdown
ACCI√ìN:
- Crear branch: optimize-prompts-ab-test
- Implementar versiones optimizadas
- Documentar m√©tricas de comparaci√≥n:
  * Tokens consumidos (input + output)
  * Task completion rate
  * Accuracy (user satisfaction proxy)
  * Execution time
```

#### Paso 4.3: Meta-Prompt Generator
```markdown
ACCI√ìN:
- Crear comando: /optimize-command [command-name]
- Usa Claude para analizar y sugerir optimizaciones
- Implementa feedback loop autom√°tico
```

---

## üìè M√©tricas de √âxito

### Cuantitativas:

| M√©trica | Baseline | Objetivo | Medici√≥n |
|---------|----------|----------|----------|
| **Total l√≠neas** | 796 | ‚â§550 | wc -l cc/{agents,commands}/* |
| **L√≠neas plan.md** | 471 | 250-300 | wc -l cc/commands/plan.md |
| **Tokens por ejecuci√≥n** | TBD | -40% | API logs |
| **Tiempo de respuesta** | TBD | -20% | Timestamps |

### Cualitativas:

| Criterio | Evaluaci√≥n |
|----------|------------|
| **Clarity** | Instrucciones son unambiguas? |
| **Completeness** | Output incluye toda info requerida? |
| **Accuracy** | Output es correcto y relevante? |
| **User Satisfaction** | Usuario necesita re-prompts? |

---

## üöÄ Cronograma de Implementaci√≥n

```mermaid
gantt
    title Optimizaci√≥n de Comandos y Agentes
    dateFormat  YYYY-MM-DD
    section Cr√≠tico
    plan.md optimizaci√≥n     :crit, p1, 2025-11-12, 3d
    A/B testing plan.md      :crit, p2, after p1, 2d
    section Medio
    code.md optimizaci√≥n     :active, c1, 2025-11-13, 2d
    section Bajo
    Agentes refinamiento     :a1, 2025-11-15, 1d
    section Sistema
    Caching implementation   :s1, after p2, 2d
    Meta-prompt tool         :s2, after s1, 2d
```

**Total estimado:** 7-10 d√≠as de desarrollo + testing

---

## üîÑ Proceso de Validaci√≥n

### Pre-Commit Checklist:

```markdown
Para cada archivo optimizado:

[ ] L√≠neas ‚â§ objetivo definido
[ ] Todas las tags sem√°nticas usan formato consistente
[ ] Ejemplos son completos pero m√≠nimos
[ ] Instrucciones son positivas (no negativas)
[ ] L√≠mites expl√≠citos especificados
[ ] Referencias en lugar de duplicaci√≥n
[ ] Testing manual: el comando/agente funciona?
[ ] Comparaci√≥n lado-a-lado: viejo vs. nuevo output
```

### A/B Testing Protocol:

```markdown
1. Ejecutar ambas versiones con mismo input
2. Comparar:
   - Tokens consumidos (usar API logs)
   - Calidad de output (scoring rubric)
   - Tiempo de ejecuci√≥n
   - Completitud (checklist de requirements)
3. Si versi√≥n nueva >= 95% calidad AND < tokens: ‚úÖ deploy
4. Si versi√≥n nueva < 95% calidad: iterar
```

---

## üéì Principios de Dise√±o (Recordatorios)

1. **Less is More**: Cada palabra debe ganar su lugar
2. **Show, Don't Tell**: Ejemplos > explicaciones largas
3. **Trust the Model**: Claude es inteligente, no sobre-especificar
4. **Positive Instructions**: Decir qu√© hacer, no qu√© evitar
5. **Structured Thinking**: Tags sem√°nticos ayudan al parsing
6. **Modular Design**: Prompt chaining > prompts monol√≠ticos
7. **Evidence-Based**: Siempre file:line o URLs
8. **Explicit Limits**: "Max X" previene outputs infinitos

---

## üìö Referencias

### Fuentes de Investigaci√≥n:

1. **Anthropic (2025)**: "Effective context engineering for AI agents"
   - Context = smallest set of high-signal tokens
   - Prompt caching reduces costs 75-90%

2. **Portkey (2025)**: "How to Optimize Token Efficiency When Prompting"
   - 30-50% reduction sin p√©rdida de calidad
   - BatchPrompt para operaciones m√∫ltiples

3. **Lakera (2025)**: "The Ultimate Guide to Prompt Engineering in 2025"
   - 150-300 palabras para tareas complejas
   - Structured formats +44% accuracy

4. **Anthropic API Updates (2025)**:
   - text_editor tool reduce tokens y latencia
   - Cache-aware rate limits

### Internal Documentation:

- `/home/user/cc/CLAUDE.md` - System architecture
- `/home/user/cc/PLUGIN_STRUCTURE.md` - Plugin standards
- `/home/user/cc/README.md` - User guide

---

## ‚úÖ Pr√≥ximos Pasos Inmediatos

1. **Revisar y aprobar este plan** con stakeholders
2. **Crear branch**: `optimize-prompts-v2`
3. **Implementar Fase 1** (plan.md) primero - mayor impacto
4. **A/B test** cada cambio antes de commit
5. **Documentar hallazgos** en cada fase
6. **Iterar** basado en m√©tricas

---

**Status:** ‚úÖ Plan completo y listo para ejecuci√≥n
**√öltima actualizaci√≥n:** 2025-11-12
**Owner:** [Your name]
**Reviewers:** [Team members]

---

## ü§ù ¬øPreguntas?

**¬øPor qu√© 40% de reducci√≥n?**
- Es el benchmark recomendado por expertos de prompt engineering 2025
- Estudios muestran que esta reducci√≥n mantiene o mejora calidad

**¬øNo perderemos funcionalidad?**
- No. Eliminamos verbosidad, no features
- Confiar en capacidad del modelo vs. sobre-especificaci√≥n

**¬øC√≥mo medimos "accuracy"?**
- Task completion rate (el comando hace lo que debe?)
- User satisfaction (necesita re-prompts?)
- Output completeness (tiene toda la info requerida?)

**¬øQu√© pasa si A/B test muestra peor rendimiento?**
- Iteramos con reducci√≥n menor (20% en vez de 40%)
- Identificamos qu√© secci√≥n caus√≥ regresi√≥n
- Revertimos solo esa secci√≥n, mantenemos otras optimizaciones
